{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Planet Competition: How to land in top 4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Material\n",
    "fastai api implementation: https://medium.com/ai-saturdays/kaggle-planet-competition-how-to-land-in-top-4-a679ff0013ba, https://github.com/irshadqemu/Kaggle-Competitions/blob/master/Planet_amazon_resnet34.ipynb\n",
    "\n",
    "p7zip-full install step: http://ask.xmodulo.com/install-7zip-linux.html\n",
    "\n",
    "data exploration & analysis(full detail): https://www.kaggle.com/anokas/data-exploration-analysis\n",
    "\n",
    "other pytorch model: https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning, https://github.com/mratsim/Amazon-Forest-Computer-Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pal = sns.color_palette()\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# File sizes')\n",
    "for f in os.listdir('./data'):\n",
    "    if not os.path.isdir('./data/' + f):\n",
    "        print(f.ljust(30) + str(round(os.path.getsize('./data/' + f) / 1000000, 2)) + 'MB')\n",
    "    else:\n",
    "        sizes = [os.path.getsize('./data/'+f+'/'+x)/1000000 for x in os.listdir('./data/' + f)]\n",
    "        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train['tags'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts = defaultdict(int)\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "\n",
    "data=[go.Bar(x=list(counts.keys()), y=list(counts.values()))]\n",
    "layout=dict(height=800, width=800, title='Distribution of training labels')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(data, filename='train-label-dist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is co-occurrence matrix?\n",
    "A co-occurrence matrix or co-occurrence distribution is a matrix that is defined over an image to be the distribution of co-occurring pixel values (grayscale values, or colors) at a given offset.\n",
    "link: https://en.wikipedia.org/wiki/Co-occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurence Matrix\n",
    "com = np.zeros([len(counts)]*2)\n",
    "for i, l in enumerate(list(counts.keys())):\n",
    "    for i2, l2 in enumerate(list(counts.keys())):\n",
    "        c = 0\n",
    "        cy = 0\n",
    "        for row in labels.values:\n",
    "            if l in row:\n",
    "                c += 1\n",
    "                if l2 in row: cy += 1\n",
    "        com[i, i2] = cy / c\n",
    "\n",
    "data=[go.Heatmap(z=com, x=list(counts.keys()), y=list(counts.keys()))]\n",
    "layout=go.Layout(height=800, width=800, title='Co-occurence matrix of training labels')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(data, filename='train-com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "new_style = {'grid': False}\n",
    "plt.rc('axes', **new_style)\n",
    "_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\n",
    "i = 0\n",
    "for f, l in df_train[:9].values:\n",
    "    img = cv2.imread('./data/train-jpg/{}.jpg'.format(f))\n",
    "    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n",
    "    #ax[i // 4, i % 4].show()\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('./')\n",
    "from fastai.conv_learner import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data' #path to folder containing data\n",
    "sz=64   #image size\n",
    "bs=64    #batch size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Criteria and Initial Model \n",
    "If you read the evaluation criteria of competition, you will know it is based on f2 score. we define metrics for model accordingly. You can find the further information about F2 score [here](https://clusteval.sdu.dk/1/clustering_quality_measures/5). \n",
    "\n",
    "For our initial model, we will be using pre-trained implementation of deep residual model renet34 which was [made public by Microsoft](https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1512.03385.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(preds, targs, start=0.17, end=0.24, step=0.01):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n",
    "                    for th in np.arange(start,end,step)])\n",
    "\n",
    "def opt_th(preds, targs, start=0.17, end=0.24, step=0.01):\n",
    "    ths = np.arange(start,end,step)\n",
    "    idx = np.argmax([fbeta_score(targs, (preds>th), 2, average='samples')\n",
    "                for th in ths])\n",
    "    return ths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[f2]\n",
    "f_model = resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prepare data Validation set\n",
    "label_csv = f'{path}train_v2.csv'\n",
    "n = len(list(open(label_csv)))-1 #total number of images\n",
    "val_idxs = get_cv_idxs(n) #it will return 20% indexes from training data set to used for val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs):\n",
    "    \"\"\"Returns data generator\"\"\"\n",
    "    tfms =  tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n",
    "    return ImageClassifierData.from_csv(path, 'train-jpg', f'{path}train_v2.csv', bs, tfms, suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg')\n",
    "data = get_data(bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = ConvLearner.pretrained(f_model, data, metrics=metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Learning Rate\n",
    "Learning rate(LR) is one of the most important hyper parameter of your model. It determines how fast or slow your model will learn.If LR is too high, model will try to learn too fast and loss function will not converge. If LR is very too low you model will take too long to converge.\n",
    "\n",
    "Finding a good learning rate using fastai library is very easy, just use the  following two commands. They will plot a graph of LR against loss function, a good value for LR will be where the slop of the loss function is highest. As we can see slope is highest between *0.1 to 1*, you can use any value in between this range. It would be a good idea to experiment with a few values in this range to find the optimal value.After experimenting with three values, 0.2 seemed to work best for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrf = mdl.lr_find()\n",
    "mdl.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total size of chips in competition is 256X256, we start training our model with 64x64 and will gradually increase the size of image as training progress. This is a very good technique to avoid our fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.2\n",
    "data = get_data(64, 64) #data generator for batch size=64, image size=64x64\n",
    "learn = ConvLearner.pretrained(f_model, data, metrics=metrics)\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the model, fastai implements a technique called **stochastic gradient descent with restarts (SGDR)**, which trains model in cycles, where each cycle consists of one or more epochs. For each cycle, it starts with LR original value and will exponentially decrease the LR([Exponential learning rate schedule](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1)) as the training progress. Second parameter in fit denotes the total number of cycles. Total number of epochs in a cycle are controlled by 2 parameter *cycle_len* and *cycle_mult* as follows.\n",
    "\n",
    "`number of epochs in first cycle = cycle_len \n",
    " number of epochs in second cycle = number of epochs in previous(first) cycle x cycle_mult\n",
    " number of epochs in third cycle =  number of epochs in previous(second) cycle x cycle_mult`\n",
    " \n",
    " \n",
    "Here is the graph the show changes in LR for each cycle in above training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the fastai will freeze the weights of all of the layers except a few last layers and the ones that it adds to fine-tune the model for your dataset. So in above epochs, all of learning is done by those unfrozen last layers.\n",
    "Next, we will unfreeze the weights of all of the layers to get more accuracy out of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrs = [lr/9, lr/3, lr]\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have noticed, I have used an array for LR instead of a single value. If you give an array of 3 elements to fastai, it will divide the layers into 3 equal sets. For each set, it will use corresponding value from array.Since we are using a pre-trained model, and in a CNN initial set of layers usually learns simple features(like find a edge, corner, etc) so we don't want our initial layers to change too much, therefore we are using the lowest LR for them.  Higher layers in CNN learns to find complex features (like geometrical patterns,faces etc), so having a higher rate for them would be good idea so they can adopt more rapidly to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train for image size128x128\n",
    "learn.set_data(get_data(128, 64))\n",
    "\n",
    "learn.freeze()\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train for image size256x256\n",
    "learn.set_data(get_data(256, 64))\n",
    "\n",
    "learn.freeze()\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai has another very good feature called Test Time Augmentation (TTA). The dea is simple; apply simple augmentation on each test image to generate five copies  of it,  and then do the prediction for each copy. You can average these prediction to get a significant(1-2%) decrease in error.\n",
    " \n",
    "So we have trained our first model, let's see how well it performs on validation set using TTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learn.predict() #returns prediction without TTA\n",
    "f2_without_TTA =f2(probs, data.val_y)\n",
    "probs,y = learn.TTA()\n",
    "probs = np.mean(probs, axis=0)\n",
    "f2_with_TTA = f2(probs, y)\n",
    "print(f\"F2 Score without TTA:{f2_without_TTA},   and with TTA:{f2_with_TTA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet34.weights.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('resnet34.weights.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our first submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our submission file, we need to place predicted labels against each image. Each image can belong to more than one class.\n",
    "\n",
    "`file_10770,agriculture clear cultivation primary road\n",
    "test_26732,agriculture clear cultivation haze primary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at an example of predictions from our validation set, you will see our original labels are in the form of 1's, 0's, but our predictions are floating point numbers. So, we need to pick a threshold for our predicts to be included in submission files (0.66 for below example). `op_th` function tries multiple threshold in a given range and returns the one which maximizes the F2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = opt_th(probs, y)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test_preds, _ = learn.TTA(is_test=True)\n",
    "preds = np.mean(test_preds, axis=0)\n",
    "classes = np.array(data.classes)\n",
    "res = np.array([\" \".join(classes[(np.where(pp>threshold))]) for pp in preds])\n",
    "filenames = np.array([os.path.basename(fn).split('.')[0] for fn in data.test_ds.fnames])\n",
    "frame=pd.DataFrame(res, index=filenames, columns=['tags'])\n",
    "frame.to_csv(f'{path}planet_amazon_restnet34_submission1.csv', index_label='image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling\n",
    "Instead of training one model, we will be training multiple models and then averaging their prediction. This techniques is always employed to get more accuracy on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensumble(nmodels):\n",
    "    models = list()\n",
    "    \n",
    "    for i in range(nmodels):\n",
    "        print(f'-----Training model: {i+1}--------')\n",
    "        val_idx = get_cv_idxs(n, val_pct=0.1, seed=12345) #use 10% of train data as val data\n",
    "        \n",
    "        data = get_data_ens(64, i, val_idx)\n",
    "        learn = ConvLearner.pretrained(f_model, data, metrics=metrics)\n",
    "        print('training for 64x64')\n",
    "        learn.fit(lr, 2, cycle_len=1, cycle_mult=2)\n",
    "        learn.unfreeze()\n",
    "        learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)\n",
    "        \n",
    "        print('training for 128x128')\n",
    "        learn.set_data(get_data_ens(128, i, val_idx))\n",
    "        learn.freeze()\n",
    "        learn.fit(lr, 2, cycle_len=1, cycle_mult=2)\n",
    "        learn.unfreeze()\n",
    "        learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)\n",
    "        \n",
    "        print('training for 256x256')\n",
    "        learn.set_data(get_data_ens(256, i, val_idx))\n",
    "        learn.freeze()\n",
    "        learn.fit(lr, 2, cycle_len=1, cycle_mult=2)\n",
    "        learn.unfreeze()\n",
    "        learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)\n",
    "        \n",
    "        \n",
    "        learn.save(f'ensem_model_{i}.weights')\n",
    "        np.savez_compressed(f'{path}models/ensem_model_{i}_validx', val_idx=val_idx)\n",
    "        models.append(learn)\n",
    "        print(f'-----Training of model {i+1} complete----')\n",
    "    return models\n",
    "        \n",
    "    \n",
    "def get_data_ens(img_sz, model_index, val_idx):\n",
    "    return  ImageClassifierData.from_csv(path, 'train-jpg', f'{path}train_v2.csv', bs, get_transform(model_index, img_sz), suffix='.jpg', val_idxs=val_idx, test_name='test-jpg')\n",
    "\n",
    "    \n",
    "    \n",
    "def get_transform(index, img_sz):\n",
    "    f_model=resnet34\n",
    "    index = (index%5)\n",
    "    print(f'get_transform--{index}: {img_sz}')\n",
    "    tfms = [\n",
    "        tfms_from_model(f_model, img_sz, aug_tfms=transforms_basic, max_zoom=1.05),\n",
    "        tfms_from_model(f_model, img_sz, aug_tfms=transforms_side_on, max_zoom=1.05),\n",
    "        tfms_from_model(f_model, img_sz, aug_tfms=transforms_top_down, max_zoom=1.05),\n",
    "        tfms_from_model(f_model, img_sz, aug_tfms=transforms_top_down, max_zoom=1.1),\n",
    "        tfms_from_model(f_model, img_sz, aug_tfms=transforms_top_down, max_zoom=1.05, crop_type=CropType.RANDOM)]\n",
    "    return tfms[index]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ens = get_ensumble(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimized Threshold\n",
    "ens_val_probs=list()\n",
    "th_list=list()\n",
    "for mdl in ens:\n",
    "    val_probs, y=mdl.TTA()\n",
    "    val_probs=np.mean(val_probs, axis=0)\n",
    "    acc = f2(val_probs, y)\n",
    "    print (f'f2 Score: {acc}')\n",
    "    th =opt_th(val_probs, y)\n",
    "    th_list.append(th)\n",
    "    ens_val_probs.append(val_probs)\n",
    "print(th_list)   \n",
    "op_th = np.mean(th_list)\n",
    "print(op_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test predictions\n",
    "ens_test_probs = list()\n",
    "for mdl in ens:\n",
    "    test_probs,_ = mdl.TTA(is_test=True)\n",
    "    test_probs = np.mean(test_probs, axis=0)\n",
    "    ens_test_probs.append(test_probs)\n",
    "ens_test_probs = np.array(ens_test_probs)\n",
    "ens_test_probs = np.mean(ens_test_probs, axis=0)\n",
    "ens_test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the submission file\n",
    "classes = np.array(ens[0].data.classes)\n",
    "res = np.array([\" \".join(classes[(np.where(pp>op_th))]) for pp in ens_test_probs])\n",
    "filenames = np.array([os.path.basename(fn).split('.')[0] for fn in ens[0].data.test_ds.fnames])\n",
    "frame=pd.DataFrame(res, index=filenames, columns=['tags'])\n",
    "frame.to_csv(f'{path}planet_amazon_restnet34_submission_ens.csv', index_label='image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Machine Learning model for calculating threshold\n",
    "When preparing submission, we used a threshold of ~0.2 to select classes for all of test images, but ideally each test image should have a separate threshold depending on the predictions values from model. I experimented with training ML model to find the better threshold but didn’t succeed. Here is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimized_threshold_list(x, y):\n",
    "    th_list = list()\n",
    "    for truth,  preds in zip(y, x):\n",
    "        steps = np.arange(0.1, 0.4, 0.01)\n",
    "        acc = np.array([accuracy_score(truth, (preds > th)) for th in steps])\n",
    "        th_list.append(steps[np.argmax(acc)])\n",
    "    return th_list\n",
    "                   \n",
    "                   \n",
    "def ml_model_threshold():\n",
    "    arr = np.load(f'{path}models/preds_probs.npz')\n",
    "    x = arr['probs']\n",
    "    y = arr['y']\n",
    "    th_list= get_optimized_threshold_list(x, y)\n",
    "    model = make_pipeline(PolynomialFeatures(2), Ridge())\n",
    "    model.fit(x, th_list)\n",
    "    print (mean_squared_error(th_list, model.predict(x)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting Machine Learning predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ml_model_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(data.classes)\n",
    "op_th_ml = model.predict(preds)\n",
    "res = np.array([\" \".join(classes[(np.where(preds[i]>op_th_ml[i]))]) for i in range(len(preds))])\n",
    "filenames = np.array([os.path.basename(fn).split('.')[0] for fn in data.test_ds.fnames])\n",
    "frame=pd.DataFrame(res, index=filenames, columns=['tags'])\n",
    "frame.to_csv(f'{path}planet_amazon_restnet34_submission2.csv', index_label='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
